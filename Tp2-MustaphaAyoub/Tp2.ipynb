{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie 1\n",
    "#Chargement des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_data(input_path, pattern):\n",
    "    with open(input_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    matches = re.findall(pattern, content, re.MULTILINE)\n",
    "    data = []\n",
    "    for match in matches:\n",
    "        numbers = match[1].replace('\\n', ' ').split()\n",
    "        numbers_float = [float(number) for number in numbers]\n",
    "        data.append(numbers_float)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "rocks_path = 'data/sonar.rocks'\n",
    "mines_path = 'data/sonar.mines'\n",
    "\n",
    "# Patterns for extracting train and test data\n",
    "train_pattern = r'\\*(CR|CM)\\d+:\\n\\{([\\d\\s\\.\\n]+)\\}'\n",
    "test_pattern = r'^(?!\\*)(CR|CM)\\d+:\\n\\{([\\d\\s\\.\\n]+)\\}'\n",
    "\n",
    "# Extracting train and test data\n",
    "rocks_train_df = extract_data(rocks_path, train_pattern)\n",
    "mines_train_df = extract_data(mines_path, train_pattern)\n",
    "rocks_train_df['Label'] = 'R'  \n",
    "mines_train_df['Label'] = 'M' \n",
    "train_df = pd.concat([rocks_train_df, mines_train_df], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "rocks_test_df = extract_data(rocks_path, test_pattern)\n",
    "mines_test_df = extract_data(mines_path, test_pattern)\n",
    "test_df = pd.concat([rocks_test_df, mines_test_df], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(len(train_df))\n",
    "print(len(test_df)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Apprentissage sur train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids appris du perceptron :\n",
      "[-116.2       32.73032   56.93142   51.60106   76.34466   83.69928\n",
      "   50.61378   27.61612  -10.66646   85.98506  102.11068  141.42002\n",
      "  155.35254  134.55974   65.70396  -22.82    -138.24972 -117.2045\n",
      "  -72.93384   24.23974    9.70172   22.50332   28.57568   -9.5305\n",
      "    6.5275   -40.56724  -74.24816  -23.00452   56.19572   88.61762\n",
      "   35.8351   -83.37392   -8.53496  -65.34444 -129.7128  -194.80048\n",
      " -262.8052  -184.44664   23.93454   49.70812  -62.98684   40.63556\n",
      "   84.64708   56.87738  106.10152  183.85794  155.5834   131.257\n",
      "  108.21384   73.00944    7.08554   12.43382   11.20378    4.53544\n",
      "    8.10166    1.6093     1.89154   -0.30814    6.70642    5.68862\n",
      "    2.43684]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def perceptron_batch(training_features, training_labels, epochs=100, learning_rate=0.7):\n",
    "    \"\"\"\n",
    "    Entraîne un perceptron en utilisant l'algorithme batch.\n",
    "\n",
    "    :param training_features: numpy.ndarray, les caractéristiques d'entraînement.\n",
    "    :param training_labels: numpy.ndarray, les étiquettes d'entraînement (doivent être -1 ou 1).\n",
    "    :param threshold: int, le nombre d'itérations pour l'entraînement.\n",
    "    :param learning_rate: float, le taux d'apprentissage.\n",
    "    :return: numpy.ndarray, les poids appris.\n",
    "    \"\"\"\n",
    "    # Initialisation des poids\n",
    "    weights = np.zeros(training_features.shape[1] + 1)\n",
    "    \n",
    "    # Entraînement\n",
    "    for _ in range(epochs):\n",
    "        # Initialisation du vecteur de mise à jour pour cette époque\n",
    "        update = np.zeros(training_features.shape[1] + 1)\n",
    "        \n",
    "        for inputs, label in zip(training_features, training_labels):\n",
    "            # Calcul de la prédiction\n",
    "            activation = np.dot(inputs, weights[1:]) + weights[0]\n",
    "            if activation >= 0:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = -1\n",
    "            \n",
    "            # Accumulation de la mise à jour basée sur l'erreur\n",
    "            update[1:] += learning_rate * (label - prediction) * inputs\n",
    "            update[0] += learning_rate * (label - prediction)\n",
    "        \n",
    "        # Mise à jour des poids à la fin de l'époque\n",
    "        weights += update\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# Préparation des données\n",
    "# Supposons que train_df est déjà défini et mélangé\n",
    "# Convertir les étiquettes 'R' et 'M' en valeurs numériques -1 et 1\n",
    "train_df['Label'] = train_df['Label'].apply(lambda x: 1 if x == 'M' else -1)\n",
    "\n",
    "# Séparation des caractéristiques et des étiquettes\n",
    "features = train_df.iloc[:, :-1].values\n",
    "labels = train_df.iloc[:, -1].values\n",
    "\n",
    "# Entraînement du perceptron\n",
    "weights = perceptron_batch(features, labels)\n",
    "\n",
    "print(\"Poids appris du perceptron :\")\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
